	Урок 1. Введение в задачу классификации. Постановка задачи и подготовка данных.

1. Приведите по 2 примера, когда лучше максимизировать Precision, а когда Recall.

Precision - как много выбранных элементов отвечают запросу.
а) Определить по кардиограмме больная ли печень у человека.
б) Проверить транзакцию на предмет мошеннических действий.

Recall - как много элементов отвечающих запросу выбрано.
а) По истории прослушиваний/просмотров пользователя определить, понравится ли пользователю следующая мелодия/фильм.
б) На основании показателей автомобиля определить нужно ли ехать в автосервис.
в) Выявить тех, кто прошел через КПП, не предъявив документы.

2. Почему мы используем F-меру, почему, например, нельзя просто взять среднее от Precision и Recall?

Мы не можем использовать просто среднее значение, потому что оно не даёт полного представления о совместной оценке Precision и Recall. Среднее значение будет одинаково равно 0.5 в случае, если оба параметра равны 0.5 и в случае, если один равен 1, а второй 0.

	Урок 2. Анализ данных и проверка статистических гипотез.

1. В чём различие между зависимыми и независимыми выборками?

Зависимые выборки - такие выборки, в которых одной единице в первой выборке строго соответствует такая же единица в другой выборке. Эти выборки непосредственно связаны друг с другом, имеют одинаковый объем и размерность. Грубо говоря, они представляют собой что-то вроде "парных наблюдений" (исследование "до" и "после", использование "с" и "без" и др).

2. Когда применяются параметрические статистические критерии, а когда — их непараметрические аналоги?

Всё зависит от распределения. Если распределение является нормальным, то применяют для аналза параметрические критерии, если же нет, то непараметрические аналоги.



	Урок 3. Построение модели классификации.

1. Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?

Micro. Характеристики сначала усредняются по классам, после чего вычисляется метрика.
Macro. Обратное к Micro. Сначала вычисляется метрика, а затем усредняются результаты.
Weighted. Применяют в очень несбалансированных выборках. В зависимости от величины вклада класса назначают, а потом применяют коэффициенты.

2. В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?

catboost
Сам создает дамми, если признаки заданы в формате category или str, удачно работает с несбалансированными выборками. Симметричные деревья строятся в ширину. Долго обучается, но хорошо реализована кросс-валидацич и перемешивание данных.

xgboost
Похож на gradient boosting, но модель построения самого дерева отличается. Xgboost реализует принцип, который показывает, насколько данные в листе похожи. Использует алгоритм предварительной сортировки. Глубина дерева зависит от прироста информации. Категориальные признаки, в отличии от catboost самостоятельно не оьрабатывает.

lightgbm
Работает на основе градиентов и объединяет признаки с наименьшими градиентами. Выборки с маленьким градиентом имеют меньшую ошибку обучения. Поэтому алгоритм вводит постоянный коэффициент-множитель для экземпляров с маленьким гадиентом, тем самым сохраняя точность для уже обученных деревьев. Категориальные признаки обрабатываются, если они заданы в формате int.


	Урок 4. Оценка и интерпретация полученной модели.

1. Расскажите, как работает регуляризация в решающих деревьях, какие параметры мы штрафуем в данных алгоритмах?

При каждом признаке мы имеем отдельный коэффициент лямбда, который стремится к нулю (посредством наложения штрафов), если признак ведет к переобучению. По сути мы просто сглаживаем кривую, которая проходит через правильные ответы.

2. По какому принципу рассчитывается "важность признака (feature_importance)" в ансамблях деревьев?

По сути важность признака показывает насколько модель станет хуже без этого признака. Ну и ниже формула из документации к DecisionTreeClassifier:

N_t / N * (impurity - N_t_R / N_t * right_impurity - N_t_L / N_t * left_impurity)

where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.